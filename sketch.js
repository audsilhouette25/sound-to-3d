let audioCtx, analyser, microphone, mediaRecorder;
let audioChunks = [];
let audioBlob, audioUrl, audioTag, sourceNode;
let brain;
let scene, camera, renderer, currentMesh, originalVertices;
let microphoneStream; // ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ì €ì¥

// ìƒíƒœ ê´€ë¦¬
let state = 'IDLE';
let recordedX = { loudness: 0, pitch: 0, brightness: 0, roughness: 0, count: 0 };
let currentX = { loudness: 0, pitch: 0, brightness: 0, roughness: 0 };
let targetY = { y1: 0.5, y2: 0.5, y3: 0.5, y4: 0.5, shape: 0 };
let currentY = { y1: 0.5, y2: 0.5, y3: 0.5, y4: 0.5, shape: 0 };

// í˜„ì¬ ë¦¬ë·° ì¤‘ì¸ ì†Œë¦¬ì˜ ìë™ ë¶„ë¥˜ ê²°ê³¼ ìºì‹œ
let cachedAutoShape = null;

// ìš°ë¦¬ë§Œì˜ ë°ì´í„° ì €ì¥ì†Œ (ml5.js ìš°íšŒ)
let customTrainingData = [];
let isModelTrained = false; // ëª¨ë¸ì´ í•™ìŠµë˜ì—ˆëŠ”ì§€ ì¶”ì 

const tempVec = new THREE.Vector3();

// DOM ìš”ì†Œ ìºì‹œ (ì„±ëŠ¥ ìµœì í™”)
let cachedDOMElements = null;

// ì˜ˆì¸¡ throttle ë° race condition ë°©ì§€
let predictionFrameCounter = 0;
let activePredictionId = 0;
const PREDICTION_INTERVAL = 5; // 5í”„ë ˆì„ë§ˆë‹¤ 1ë²ˆ ì˜ˆì¸¡ (60fps â†’ 12 predictions/sec)

// í˜•íƒœ ë³€ê²½ ì¶”ì 
let previousShape = -1;

// ë¦¬ì‚¬ì´ì¦ˆ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì°¸ì¡°
let resizeHandler = null;

// ë””ë°”ìš´ìŠ¤ íƒ€ì´ë¨¸
let shapeChangeTimer = null;

// ë‹¤ì–‘í•œ ê¸°ë³¸ í˜•íƒœ ì •ì˜
const SHAPES = {
    SPHERE: 0,
    CUBE: 1,
    TORUS: 2,
    CONE: 3,
    CYLINDER: 4,
    OCTAHEDRON: 5
};

const SHAPE_NAMES = ['Sphere', 'Cube', 'Torus', 'Cone', 'Cylinder', 'Octahedron'];

// [ì¶”ê°€ë¨] ìƒìˆ˜ ì •ì˜ (ë§¤ì§ ë„˜ë²„ ì œê±°)
const AUDIO_CONSTANTS = {
    LOUDNESS_NORMALIZER: 5,
    LOUDNESS_MULTIPLIER: 10,
    PITCH_NORMALIZER: 40,
    ROUGHNESS_NORMALIZER: 30,
    MIN_TRAINING_SAMPLES: 0,  // AIê°€ ì²˜ìŒë¶€í„° ì˜ˆì¸¡, ë°ì´í„° ì¶”ê°€ì‹œ ì ì§„ì  ê°œì„ 
    MIN_PREDICTION_SAMPLES: 0  // í•™ìŠµ ë°ì´í„° ì—†ì–´ë„ ì˜ˆì¸¡ í—ˆìš©
};

// ì†Œë¦¬ íŠ¹ì„±ì— ë”°ë¼ ìë™ìœ¼ë¡œ í˜•íƒœ ë¶„ë¥˜
function autoClassifyShape(loudness, pitch, brightness, roughness) {
    // [ì¶”ê°€ë¨] ì…ë ¥ ê²€ì¦
    if (typeof loudness !== 'number' || isNaN(loudness) ||
        typeof pitch !== 'number' || isNaN(pitch) ||
        typeof brightness !== 'number' || isNaN(brightness) ||
        typeof roughness !== 'number' || isNaN(roughness)) {
        console.error('Invalid input to autoClassifyShape:', { loudness, pitch, brightness, roughness });
        return SHAPES.SPHERE; // ê¸°ë³¸ê°’ ë°˜í™˜
    }

    // ì •ê·œí™”ëœ ê°’ë“¤ë¡œ ë¶„ë¥˜ (0-1 ë²”ìœ„ ê°€ì •)
    const normalizedLoudness = Math.min(1, Math.max(0, loudness / AUDIO_CONSTANTS.LOUDNESS_NORMALIZER));
    const normalizedPitch = Math.min(1, Math.max(0, pitch));
    const normalizedBrightness = Math.min(1, Math.max(0, brightness));
    const normalizedRoughness = Math.min(1, Math.max(0, roughness));

    console.log('ğŸµ Audio features:', {
        loudness: loudness.toFixed(3),
        pitch: pitch.toFixed(3),
        brightness: brightness.toFixed(3),
        roughness: roughness.toFixed(3),
        normalized: {
            loudness: normalizedLoudness.toFixed(3),
            pitch: normalizedPitch.toFixed(3),
            brightness: normalizedBrightness.toFixed(3),
            roughness: normalizedRoughness.toFixed(3)
        }
    });

    // ë¶„ë¥˜ ë¡œì§:
    // - Sphere (0): ë¶€ë“œëŸ½ê³  ê· ì¼í•œ ì†Œë¦¬ (ë‚®ì€ roughness, ì¤‘ê°„ pitch)
    // - Cube (1): ê°ì§„, ëª…í™•í•œ ì†Œë¦¬ (ë†’ì€ brightness, ì¤‘ê°„ roughness)
    // - Torus (2): íšŒì „í•˜ëŠ” ëŠë‚Œì˜ ì†Œë¦¬ (ì¤‘ê°„-ë†’ì€ pitch, ë³€í™”ê°€ ìˆëŠ”)
    // - Cone (3): ë¾°ì¡±í•˜ê³  ë‚ ì¹´ë¡œìš´ ì†Œë¦¬ (ë†’ì€ pitch, ë†’ì€ brightness)
    // - Cylinder (4): ì¼ì •í•˜ê³  ì—°ì†ì ì¸ ì†Œë¦¬ (ë‚®ì€ roughness, ì¼ì •í•œ pitch)
    // - Octahedron (5): ë³µì¡í•˜ê³  ë¶ˆê·œì¹™í•œ ì†Œë¦¬ (ë†’ì€ roughness, ë³€í™” ë§ìŒ)

    const scores = [0, 0, 0, 0, 0, 0];

    // Sphere: ë¶€ë“œëŸ½ê³  ì¤‘ê°„ ë²”ìœ„
    scores[0] = (1 - normalizedRoughness) * 0.4 +
                (normalizedPitch > 0.3 && normalizedPitch < 0.7 ? 0.6 : 0);

    // Cube: ë°ê³  ì ë‹¹íˆ ê±°ì¹œ
    scores[1] = normalizedBrightness * 0.5 +
                (normalizedRoughness > 0.3 && normalizedRoughness < 0.7 ? 0.5 : 0);

    // Torus: ì¤‘ê°„-ë†’ì€ pitch, íšŒì „ê°
    scores[2] = (normalizedPitch > 0.5 ? 0.6 : 0.2) +
                normalizedLoudness * 0.4;

    // Cone: ë†’ê³  ë‚ ì¹´ë¡œìš´
    scores[3] = (normalizedPitch > 0.6 ? 0.5 : 0) +
                (normalizedBrightness > 0.6 ? 0.5 : 0);

    // Cylinder: ì¼ì •í•˜ê³  ì—°ì†ì 
    scores[4] = (1 - normalizedRoughness) * 0.5 +
                (normalizedLoudness > 0.3 ? 0.5 : 0);

    // Octahedron: ë³µì¡í•˜ê³  ê±°ì¹œ
    scores[5] = normalizedRoughness * 0.6 +
                (normalizedBrightness > 0.5 ? 0.4 : 0.2);

    console.log('ğŸ“Š Shape scores:', scores.map((s, i) => `${SHAPE_NAMES[i]}: ${s.toFixed(3)}`).join(', '));

    // ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ í˜•íƒœ ë°˜í™˜
    let maxScore = -1;
    let bestShape = 0;
    for (let i = 0; i < 6; i++) {
        if (scores[i] > maxScore) {
            maxScore = scores[i];
            bestShape = i;
        }
    }

    console.log(`âœ… Selected: ${SHAPE_NAMES[bestShape]} (score: ${maxScore.toFixed(3)})`);
    return bestShape;
}

// DOM ìš”ì†Œ ìºì‹± í•¨ìˆ˜ (ì„±ëŠ¥ ìµœì í™”)
function cacheDOMElements() {
    cachedDOMElements = {
        autoShape: document.getElementById('auto-shape'),
        y1: document.getElementById('y1'),
        y2: document.getElementById('y2'),
        y3: document.getElementById('y3'),
        y4: document.getElementById('y4'),
        shapeSelector: document.getElementById('shape-selector'),
        shapeName: document.getElementById('shape-name'),
        btnMain: document.getElementById('btn-main'),
        btnPlay: document.getElementById('btn-play'),
        btnConfirm: document.getElementById('btn-confirm'),
        labelingZone: document.getElementById('labeling-zone'),
        status: document.getElementById('status')
    };
}

// [ì¶”ê°€ë¨] ì¤‘ë³µ ì œê±°: ìë™ ë¶„ë¥˜ ë¡œì§ì„ ê³µí†µ í•¨ìˆ˜ë¡œ ì¶”ì¶œ
function performAutoClassification() {
    if (!recordedX || recordedX.count === 0) {
        console.warn('No recorded audio data for auto-classification');
        return;
    }

    // [ìˆ˜ì •ë¨] brainì´ ìˆìœ¼ë©´ í•­ìƒ AI ì˜ˆì¸¡ ì‹œë„ (í•™ìŠµ ì—¬ë¶€ ë¬´ê´€)
    // í•™ìŠµ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ëœë¤ ì´ˆê¸° weightsë¡œ ì˜ˆì¸¡ â†’ ì ì§„ì  ê°œì„ 
    if (brain) {
        // AI ì˜ˆì¸¡ ëª¨ë“œ (í•™ìŠµ ë°ì´í„° 0ê°œì—¬ë„ ê°€ëŠ¥)
        brain.predict([recordedX.loudness, recordedX.pitch, recordedX.brightness, recordedX.roughness], (err, res) => {
            if (!err && res && res.length >= 5) {
                // [ìˆ˜ì •ë¨] ëª¨ë“  ì˜ˆì¸¡ê°’ì— ëŒ€í•œ NaN ì²´í¬
                const y1 = res[0].value;
                const y2 = res[1].value;
                const y3 = res[2].value;
                const y4 = res[3].value;
                const rawShapeValue = res[4].value;

                // NaNì´ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ fallback ì‚¬ìš©
                if (isNaN(y1) || isNaN(y2) || isNaN(y3) || isNaN(y4) || isNaN(rawShapeValue)) {
                    console.warn('âš ï¸ AI prediction returned NaN values. Using rule-based classification as fallback.');
                    console.log('  Predicted values:', { y1, y2, y3, y4, shape: rawShapeValue });

                    const fallbackShape = autoClassifyShape(
                        recordedX.loudness,
                        recordedX.pitch,
                        recordedX.brightness,
                        recordedX.roughness
                    );

                    // Fallback: ê¸°ë³¸ê°’ ì‚¬ìš©
                    targetY.y1 = 0.5;
                    targetY.y2 = 0.5;
                    targetY.y3 = 0.5;
                    targetY.y4 = 0.5;
                    targetY.shape = fallbackShape;
                    cachedAutoShape = fallbackShape;
                    document.getElementById('shape-selector').value = fallbackShape;
                    document.getElementById('shape-name').innerText = SHAPE_NAMES[fallbackShape];
                    createShape(fallbackShape);
                    console.log(`ğŸ“ Fallback to rule-based: shape=${SHAPE_NAMES[fallbackShape]}, y1-y4=0.5`);
                    return;
                }

                // AI ì˜ˆì¸¡ê°’ìœ¼ë¡œ y1~y4, shape ëª¨ë‘ ì„¤ì •
                targetY.y1 = y1;
                targetY.y2 = y2;
                targetY.y3 = y3;
                targetY.y4 = y4;

                const predictedShape = Math.round(Math.max(0, Math.min(5, rawShapeValue)));
                targetY.shape = predictedShape;
                cachedAutoShape = predictedShape;
                document.getElementById('shape-selector').value = predictedShape;
                document.getElementById('shape-name').innerText = SHAPE_NAMES[predictedShape];
                createShape(predictedShape);
                console.log(`ğŸ¤– AI-predicted shape: ${SHAPE_NAMES[predictedShape]} (raw: ${rawShapeValue.toFixed(3)})`);
            }
        });
    } else {
        // ê·œì¹™ ê¸°ë°˜ ë¶„ë¥˜ ëª¨ë“œ
        const autoShape = autoClassifyShape(
            recordedX.loudness,
            recordedX.pitch,
            recordedX.brightness,
            recordedX.roughness
        );
        targetY.shape = autoShape;
        cachedAutoShape = autoShape;
        document.getElementById('shape-selector').value = autoShape;
        document.getElementById('shape-name').innerText = SHAPE_NAMES[autoShape];
        createShape(autoShape);
        console.log(`ğŸ“ Rule-based shape: ${SHAPE_NAMES[autoShape]}`);
    }
}

window.onload = () => { initThree(); };

function initThree() {
    const container = document.getElementById('three-container');
    scene = new THREE.Scene();

    // ì»¨í…Œì´ë„ˆ í¬ê¸° ê¸°ì¤€ìœ¼ë¡œ ì¹´ë©”ë¼ ì„¤ì •
    const containerWidth = container.clientWidth;
    const containerHeight = container.clientHeight;
    camera = new THREE.PerspectiveCamera(75, containerWidth / containerHeight, 0.1, 1000);

    updateCameraPosition();

    renderer = new THREE.WebGLRenderer({ antialias: true });
    renderer.setSize(containerWidth, containerHeight);
    container.appendChild(renderer.domElement);

    // ê¸°ë³¸ í˜•íƒœë¡œ êµ¬ì²´ ìƒì„±
    createShape(SHAPES.SPHERE);

    scene.add(new THREE.DirectionalLight(0xffffff, 1), new THREE.AmbientLight(0x222222));

    // ì°½ í¬ê¸° ë³€ê²½ ì‹œ ì»¨í…Œì´ë„ˆ í¬ê¸°ì— ë§ì¶° ì—…ë°ì´íŠ¸ (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)
    if (resizeHandler) {
        window.removeEventListener('resize', resizeHandler);
    }

    resizeHandler = () => {
        const containerWidth = container.clientWidth;
        const containerHeight = container.clientHeight;
        camera.aspect = containerWidth / containerHeight;
        camera.updateProjectionMatrix();
        renderer.setSize(containerWidth, containerHeight);
        updateCameraPosition();
    };

    window.addEventListener('resize', resizeHandler);

    animate();
}

// ì¹´ë©”ë¼ ìœ„ì¹˜ ì—…ë°ì´íŠ¸ í•¨ìˆ˜
function updateCameraPosition() {
    // ì¹´ë©”ë¼ë¥¼ í™”ë©´ ì¤‘ì•™ì— ë°°ì¹˜
    camera.position.set(0, 0, 3.5);
}

// í˜•íƒœ ìƒì„± í•¨ìˆ˜
function createShape(shapeType) {
    // ê¸°ì¡´ ë©”ì‰¬ ì œê±°
    if (currentMesh) {
        scene.remove(currentMesh);
        currentMesh.geometry.dispose();
        currentMesh.material.dispose();
    }

    let geometry;
    switch(shapeType) {
        case SHAPES.SPHERE:
            geometry = new THREE.SphereGeometry(1, 48, 48);
            break;
        case SHAPES.CUBE:
            geometry = new THREE.BoxGeometry(1.5, 1.5, 1.5, 32, 32, 32);
            break;
        case SHAPES.TORUS:
            geometry = new THREE.TorusGeometry(0.8, 0.4, 32, 64);
            break;
        case SHAPES.CONE:
            geometry = new THREE.ConeGeometry(1, 2, 48, 32);
            break;
        case SHAPES.CYLINDER:
            geometry = new THREE.CylinderGeometry(0.8, 0.8, 2, 48, 32);
            break;
        case SHAPES.OCTAHEDRON:
            geometry = new THREE.OctahedronGeometry(1.2, 4);
            break;
        default:
            geometry = new THREE.SphereGeometry(1, 48, 48);
    }

    const material = new THREE.MeshStandardMaterial({
        color: 0x00ffcc,
        wireframe: true,
        metalness: 0.3,
        roughness: 0.4
    });

    currentMesh = new THREE.Mesh(geometry, material);
    // ì˜¤ë¸Œì íŠ¸ëŠ” ì¤‘ì•™ì— ë°°ì¹˜
    scene.add(currentMesh);
    originalVertices = currentMesh.geometry.attributes.position.array.slice();
}

async function initEngine() {
    updateStatus('statusInit', 'status-idle');

    audioCtx = new (window.AudioContext || window.webkitAudioContext)();

    // ë§ˆì´í¬ëŠ” ë…¹ìŒ ì‹œì‘í•  ë•Œë§Œ ì¼œë„ë¡ ë³€ê²½ (ì‚¬ìš©ì ìš”ì²­)
    // microphoneStreamì€ nullë¡œ ì‹œì‘

    analyser = audioCtx.createAnalyser();
    analyser.fftSize = 512;

    brain = ml5.neuralNetwork({
        inputs: 4,
        outputs: 5,
        task: 'regression',
        debug: false,
        hiddenUnits: 8,           // ë” ì‘ì€ hidden layer (ê³¼ì í•© ë°©ì§€)
        learningRate: 0.01,       // ë‚®ì€ learning rate (ì•ˆì •ì  í•™ìŠµ)
        activationHidden: 'relu', // ReLU activation (í•™ìŠµ ì•ˆì •ì„±)
        activationOutput: 'sigmoid' // 0-1 ë²”ìœ„ ì¶œë ¥ ë³´ì¥
    });

    console.log('Brain created, waiting for initialization...');

    // ml5.js neuralNetworkëŠ” ìƒì„± ì§í›„ì—ëŠ” brain.dataê°€ undefinedì¼ ìˆ˜ ìˆìŒ
    // brain.data.trainingì´ ì‹¤ì œë¡œ ì¡´ì¬í•  ë•Œê¹Œì§€ ëŒ€ê¸° (ìµœëŒ€ 10ì´ˆ)
    let retryCount = 0;
    const maxRetries = 200; // 50ms * 200 = 10ì´ˆ

    const waitForBrainReady = () => {
        retryCount++;

        if (brain.data && Array.isArray(brain.data.training)) {
            console.log('âœ“ Brain initialized successfully');
            console.log('brain.data.training length:', brain.data.training.length);

            // ì €ì¥ëœ í•™ìŠµ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
            loadTrainingData();

            // ë°ì´í„° ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸
            updateDataCount();

            const finalCount = brain.data.training ? brain.data.training.length : 0;
            console.log(`Initialization complete. Loaded ${finalCount} training samples.`);
        } else if (retryCount >= maxRetries) {
            console.error('CRITICAL: Brain initialization timeout after 10 seconds');
            alert('Failed to initialize neural network. Please refresh the page.');
        } else {
            // ì•„ì§ ì´ˆê¸°í™” ì•ˆë¨, ê³„ì† ëŒ€ê¸°
            setTimeout(waitForBrainReady, 50);
        }
    };

    // ì´ˆê¸°í™” ëŒ€ê¸° ì‹œì‘
    setTimeout(waitForBrainReady, 100);

    // DOM ìš”ì†Œ ìºì‹± (ì„±ëŠ¥ ìµœì í™”)
    cacheDOMElements();

    document.getElementById('btn-engine').style.display = 'none';
    document.getElementById('btn-main').style.display = 'block';
    document.getElementById('save-load-zone').style.display = 'block';

    updateStatus('statusActive', 'status-idle');
}

// ìƒíƒœ ì—…ë°ì´íŠ¸ í•¨ìˆ˜
function updateStatus(messageKey, className) {
    const statusEl = document.getElementById('status');
    const t = translations[currentLang];

    // messageKeyê°€ translationsì— ìˆìœ¼ë©´ ë²ˆì—­ëœ í…ìŠ¤íŠ¸ ì‚¬ìš©
    const message = t[messageKey] || messageKey;

    statusEl.innerText = message;
    statusEl.className = 'status-badge ' + className;
}

async function handleRecord() {
    if (state === 'IDLE' || state === 'REVIEWING') await startRecording();
    else if (state === 'RECORDING') stopRecording();
}

async function startRecording() {
    console.log('=== START RECORDING ===');
    state = 'RECORDING';
    audioChunks = [];
    recordedX = { loudness: 0, pitch: 0, brightness: 0, roughness: 0, count: 0 };
    cachedAutoShape = null; // ìƒˆ ë…¹ìŒ ì‹œì‘í•˜ë©´ ìºì‹œ ì´ˆê¸°í™”

    console.log('Initial recordedX:', recordedX);
    console.log('analyser exists:', !!analyser);
    console.log('audioCtx state:', audioCtx ? audioCtx.state : 'no audioCtx');

    // ì´ì „ ë…¹ìŒ ë°ì´í„° ì‚­ì œ
    if(audioTag) {
        audioTag.pause();
        audioTag = null;
    }
    if(audioUrl) {
        URL.revokeObjectURL(audioUrl);
        audioUrl = null;
    }
    if(sourceNode) {
        sourceNode.disconnect();
        sourceNode = null;
    }

    // [ìˆ˜ì •] ë§¤ë²ˆ ìƒˆë¡œìš´ ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ìš”ì²­ (stopRecordingì—ì„œ ëŠì—ˆìœ¼ë¯€ë¡œ)
    console.log('ë§ˆì´í¬ ìƒˆë¡œ ì¼œê¸°...');
    try {
        microphoneStream = await navigator.mediaDevices.getUserMedia({ audio: true });

        // AudioContextê°€ suspended ìƒíƒœë©´ resume
        if (audioCtx.state === 'suspended') {
            await audioCtx.resume();
            console.log('AudioContext resumed');
        }

        microphone = audioCtx.createMediaStreamSource(microphoneStream);
        microphone.connect(analyser);
        console.log('âœ“ Microphone connected to analyser');
        console.log('âœ“ microphone.mediaStream active:', microphoneStream.active);
        console.log('âœ“ microphone.mediaStream tracks:', microphoneStream.getTracks().map(t => t.enabled));
    } catch (err) {
        console.error('Microphone access error:', err);
        alert('Failed to access microphone. Please check permissions and try again.');
        state = 'IDLE';
        updateStatus('statusActive', 'status-idle');
        return;
    }

    // ìƒˆ MediaRecorder ìƒì„±
    mediaRecorder = new MediaRecorder(microphoneStream);
    mediaRecorder.ondataavailable = (e) => audioChunks.push(e.data);
    mediaRecorder.onstop = saveRecording;

    mediaRecorder.start();
    const t = translations[currentLang];
    document.getElementById('btn-main').innerText = t.btnStop;
    document.getElementById('labeling-zone').style.display = "none";
    document.getElementById('btn-play').style.display = "none";

    updateStatus('statusRecording', 'status-recording');
}

function stopRecording() {
    console.log(`Stopping recording... recordedX.count so far: ${recordedX.count}`);

    mediaRecorder.stop();
    state = 'REVIEWING';

    // ë…¹ìŒ ì¢…ë£Œ ì‹œ ë§ˆì´í¬ ì¤‘ë‹¨ (ì‚¬ìš©ì ìš”ì²­)
    // ë‹¨, analyserëŠ” ì—°ê²° ìœ ì§€í•˜ì—¬ ì¬ìƒ ì‹œ ë¶„ì„ ê°€ëŠ¥í•˜ê²Œ í•¨
    if (microphoneStream) {
        microphoneStream.getTracks().forEach(track => track.stop());
        microphoneStream = null;
        console.log('ë§ˆì´í¬ êº¼ì§');
    }
    if (microphone) {
        microphone.disconnect();
        microphone = null;
    }

    const t = translations[currentLang];
    document.getElementById('btn-main').innerText = t.btnReRecord;
    document.getElementById('labeling-zone').style.display = "block";
    document.getElementById('btn-confirm').style.display = "block";
    document.getElementById('btn-play').style.display = "inline-block";
    document.getElementById('btn-play').innerText = t.btnPlay;

    updateStatus('statusReview', 'status-review');

    // [ìˆ˜ì •ë¨] shape-nameì„ ì´ˆê¸° ìƒíƒœë¡œ ì„¤ì • (undefined ë°©ì§€)
    if (!document.getElementById('auto-shape').checked) {
        // ìˆ˜ë™ ëª¨ë“œë©´ í˜„ì¬ ìŠ¬ë¼ì´ë” ê°’ìœ¼ë¡œ í‘œì‹œ
        const currentShape = parseInt(document.getElementById('shape-selector').value);
        document.getElementById('shape-name').innerText = SHAPE_NAMES[currentShape];
    }
    // Auto ëª¨ë“œì¼ ë•ŒëŠ” saveRecording ì½œë°±ì—ì„œ ì²˜ë¦¬
}

function saveRecording() {
    audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
    audioUrl = URL.createObjectURL(audioBlob);

    // ì˜¤ë””ì˜¤ íƒœê·¸ ì¤€ë¹„ë§Œ í•˜ê³  ìë™ ì¬ìƒí•˜ì§€ ì•ŠìŒ
    audioTag = new Audio(audioUrl);
    audioTag.loop = true;

    // ë…¹ìŒëœ í‰ê· ê°’ ì €ì¥ (í•™ìŠµìš©)
    if (recordedX.count > 0) {
        recordedX.loudness /= recordedX.count;
        recordedX.pitch /= recordedX.count;
        recordedX.brightness /= recordedX.count;
        recordedX.roughness /= recordedX.count;
    }

    console.log('saveRecording - recordedX after processing:', recordedX);

    // [ì¶”ê°€ë¨] ìë™ ë¶„ë¥˜ê°€ ì¼œì ¸ ìˆìœ¼ë©´ í‰ê·  ê³„ì‚° í›„ ì‹¤í–‰
    if (document.getElementById('auto-shape').checked) {
        setTimeout(() => {
            performAutoClassification();
        }, 50); // recordedX í‰ê·  ê³„ì‚° ì™„ë£Œ í›„ ì‹¤í–‰
    }
}

// ë…¹ìŒ ì¬ìƒ/ì¼ì‹œì •ì§€ í† ê¸€
function togglePlayback() {
    if (!audioTag) return;

    const t = translations[currentLang];

    if (audioTag.paused) {
        // ì¬ìƒ ì‹œì‘
        if (sourceNode) sourceNode.disconnect();
        sourceNode = audioCtx.createMediaElementSource(audioTag);
        sourceNode.connect(analyser);
        analyser.connect(audioCtx.destination);

        audioTag.play();
        document.getElementById('btn-play').innerText = t.btnPause;
    } else {
        // ì¼ì‹œì •ì§€
        audioTag.pause();
        document.getElementById('btn-play').innerText = t.btnPlay;
    }
}

function animate() {
    requestAnimationFrame(animate);

    if (analyser) {
        analyzeAudio();

        // [ìµœì í™”] ë¦¬ë·° ëª¨ë“œì¼ ë•ŒëŠ” ìŠ¬ë¼ì´ë” ê°’ì„ ì¦‰ì‹œ targetYì— ë°˜ì˜
        // ë‹¨, Auto-classifyê°€ ì¼œì ¸ìˆìœ¼ë©´ ìŠ¬ë¼ì´ë” ê°’ ë¬´ì‹œ
        // DOM ì¿¼ë¦¬ë¥¼ ìºì‹œëœ ìš”ì†Œë¡œ ëŒ€ì²´í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ (360 queries/sec â†’ 6 queries/sec)
        if (state === 'REVIEWING') {
            if (cachedDOMElements && !cachedDOMElements.autoShape.checked) {
                // ìˆ˜ë™ ëª¨ë“œ: ìŠ¬ë¼ì´ë” ê°’ ì‚¬ìš©
                targetY.y1 = parseFloat(cachedDOMElements.y1.value);
                targetY.y2 = parseFloat(cachedDOMElements.y2.value);
                targetY.y3 = parseFloat(cachedDOMElements.y3.value);
                targetY.y4 = parseFloat(cachedDOMElements.y4.value);
                targetY.shape = parseFloat(cachedDOMElements.shapeSelector.value);
            }
            // Auto ëª¨ë“œì¼ ë•ŒëŠ” stopRecording()ì—ì„œ ì„¤ì •í•œ ê°’ ìœ ì§€
        } else if (brain) {
            // [ìˆ˜ì •ë¨] brainì´ ìˆìœ¼ë©´ í•­ìƒ ì˜ˆì¸¡ (í•™ìŠµ ë°ì´í„° ì—†ì–´ë„ ê°€ëŠ¥)
            // [ìµœì í™”] AI ì˜ˆì¸¡ throttle: 5í”„ë ˆì„ë§ˆë‹¤ 1ë²ˆë§Œ ì‹¤í–‰ (60fps â†’ 12 predictions/sec)
            predictionFrameCounter++;
            if (predictionFrameCounter >= PREDICTION_INTERVAL) {
                predictionFrameCounter = 0;

                // [ìµœì í™”] Race condition ë°©ì§€: ì˜ˆì¸¡ IDë¡œ ì˜¤ë˜ëœ ê²°ê³¼ ë¬´ì‹œ
                const currentPredictionId = ++activePredictionId;
                const features = [currentX.loudness, currentX.pitch, currentX.brightness, currentX.roughness];

                brain.predict(features, (err, res) => {
                    // ìƒˆë¡œìš´ ì˜ˆì¸¡ì´ ì´ë¯¸ ì‹œì‘ë˜ì—ˆìœ¼ë©´ ì´ ê²°ê³¼ ë¬´ì‹œ
                    if (currentPredictionId !== activePredictionId) return;

                    if(!err && res && res.length >= 5) {
                        // [ì¶”ê°€ë¨] NaN ê²€ì¦: ì‹¤ì‹œê°„ ì˜ˆì¸¡ì—ì„œë„ NaN ë°©ì§€
                        const y1 = res[0].value;
                        const y2 = res[1].value;
                        const y3 = res[2].value;
                        const y4 = res[3].value;
                        const shape = res[4].value;

                        // ìœ íš¨í•œ ê°’ë§Œ ì ìš©
                        if (!isNaN(y1)) targetY.y1 = y1;
                        if (!isNaN(y2)) targetY.y2 = y2;
                        if (!isNaN(y3)) targetY.y3 = y3;
                        if (!isNaN(y4)) targetY.y4 = y4;
                        if (!isNaN(shape)) targetY.shape = shape;
                    }
                });
            }
        }

        // ì‹œê°í™” ìˆ˜ì¹˜ ë¶€ë“œëŸ½ê²Œ ì „ì´ (ë¦¬ë·° ëª¨ë“œì—ì„œëŠ” ë” ë¹ ë¥´ê²Œ)
        const lerpSpeed = (state === 'REVIEWING') ? 0.3 : 0.1;
        currentY.y1 += (targetY.y1 - currentY.y1) * lerpSpeed;
        currentY.y2 += (targetY.y2 - currentY.y2) * lerpSpeed;
        currentY.y3 += (targetY.y3 - currentY.y3) * lerpSpeed;
        currentY.y4 += (targetY.y4 - currentY.y4) * lerpSpeed;
        currentY.shape += (targetY.shape - currentY.shape) * lerpSpeed;

        // [ë²„ê·¸ ìˆ˜ì •] í˜•íƒœ ë³€ê²½ ê°ì§€ ë¡œì§ ê°œì„ 
        const roundedShape = Math.round(currentY.shape);
        if (roundedShape !== previousShape && roundedShape >= 0 && roundedShape <= 5) {
            previousShape = roundedShape;
            createShape(roundedShape);
        }

        // [ìˆ˜ì •] ì‹œê°í™”:
        // - REVIEWING ìƒíƒœì´ê³  ì˜¤ë””ì˜¤ë¥¼ ì¬ìƒ ì¤‘ì´ë©´: ì¬ìƒë˜ëŠ” ì˜¤ë””ì˜¤ì˜ ì‹¤ì‹œê°„ ë¶„ì„ê°’ ì‚¬ìš©
        // - REVIEWING ìƒíƒœì´ê³  ì¬ìƒ ì•ˆ í•˜ë©´: ë…¹ìŒëœ í‰ê· ê°’ ì‚¬ìš© (ì •ì  í‘œì‹œ)
        // - RECORDING ìƒíƒœ: ë§ˆì´í¬ ì‹¤ì‹œê°„ ê°’ ì‚¬ìš©
        let visualLoudness = currentX.loudness;
        if (state === 'REVIEWING' && recordedX.count > 0) {
            // ì¬ìƒ ì¤‘ì´ ì•„ë‹ˆë©´ í‰ê· ê°’ ì‚¬ìš©
            if (!audioTag || audioTag.paused) {
                visualLoudness = recordedX.loudness;
            }
        }
        updateVisuals(visualLoudness);
    }
    renderer.render(scene, camera);
}

function analyzeAudio() {
    const data = new Uint8Array(analyser.frequencyBinCount);
    const time = new Uint8Array(analyser.frequencyBinCount);
    analyser.getByteFrequencyData(data);
    analyser.getByteTimeDomainData(time);

    // ë””ë²„ê¹…: ì²« ë…¹ìŒ í”„ë ˆì„ì—ì„œ raw data í™•ì¸
    if (state === 'RECORDING' && recordedX.count === 0) {
        console.log('First recording frame - raw audio data check:');
        console.log('  frequencyBinCount:', analyser.frequencyBinCount);
        console.log('  time data sample:', Array.from(time.slice(0, 10)));
        console.log('  freq data sample:', Array.from(data.slice(0, 10)));
    }

    // [ê°œì„ ë¨] ë³¼ë¥¨/loudness ê³„ì‚° (RMS)
    let s = 0;
    for(let v of time) {
        let n = (v - 128) / 128;
        s += n * n;
    }
    currentX.loudness = time.length > 0 ? Math.sqrt(s / time.length) * AUDIO_CONSTANTS.LOUDNESS_MULTIPLIER : 0;

    // [ê°œì„ ë¨] í”¼ì¹˜/ë°ê¸° ê³„ì‚° (ê°€ì¤‘ í‰ê· ) - division by zero ë°©ì§€
    let te = 0, we = 0;
    for(let i = 0; i < data.length; i++) {
        we += i * data[i];
        te += data[i];
    }
    currentX.pitch = currentX.brightness = te > 0 ? (we / te) / AUDIO_CONSTANTS.PITCH_NORMALIZER : 0;

    // [ê°œì„ ë¨] ê±°ì¹ ê¸°/roughness ê³„ì‚° (ì˜ì  êµì°¨ìœ¨)
    let z = 0;
    for(let i = 1; i < time.length; i++) {
        if(time[i] > 128 && time[i-1] <= 128) z++;
    }
    currentX.roughness = time.length > 0 ? z / AUDIO_CONSTANTS.ROUGHNESS_NORMALIZER : 0;

    if (state === 'RECORDING') {
        recordedX.loudness += currentX.loudness;
        recordedX.pitch += currentX.pitch;
        recordedX.brightness += currentX.brightness;
        recordedX.roughness += currentX.roughness;
        recordedX.count++;

        // ë””ë²„ê¹…: ì²˜ìŒ ëª‡ í”„ë ˆì„ë§Œ ë¡œê·¸
        if (recordedX.count <= 3) {
            console.log(`Recording frame ${recordedX.count}:`, {
                loudness: currentX.loudness.toFixed(3),
                pitch: currentX.pitch.toFixed(3),
                brightness: currentX.brightness.toFixed(3),
                roughness: currentX.roughness.toFixed(3)
            });
        }
    }
}

function updateVisuals(loudness) {
    if (!currentMesh) return;

    const pos = currentMesh.geometry.attributes.position;
    const t = Date.now() * 0.001;
    const shapeType = Math.round(currentY.shape);

    for (let i = 0; i < pos.count; i++) {
        const i3 = i * 3;
        const ox = originalVertices[i3];
        const oy = originalVertices[i3 + 1];
        const oz = originalVertices[i3 + 2];

        tempVec.set(ox, oy, oz);

        // í˜•íƒœë³„ ê³ ìœ í•œ ë³€í˜• ë¡œì§
        let displacement = 0;

        switch(shapeType) {
            case SHAPES.SPHERE:
                // êµ¬: ë°©ì‚¬í˜• íŒŒë™
                tempVec.normalize();
                const sphereWave = Math.sin(tempVec.x * 3 + tempVec.y * 2 + t * (1 + currentY.y4 * 3)) * currentY.y2;
                const sphereRough = (Math.random() - 0.5) * currentY.y3 * 0.1;
                displacement = 1 + sphereWave * 0.3 + sphereRough + loudness * 0.3;
                tempVec.multiplyScalar(displacement);
                break;

            case SHAPES.CUBE:
                // ì •ìœ¡ë©´ì²´: ë©´ ë‹¨ìœ„ í„ìŠ¤
                const cubeWave = Math.sin((Math.abs(ox) + Math.abs(oy) + Math.abs(oz)) * 2 + t * 2) * currentY.y2;
                const faceNoise = (Math.sin(ox * 10 + t) * Math.cos(oy * 10 + t)) * currentY.y3 * 0.1;
                displacement = 1 + cubeWave * 0.2 + faceNoise + loudness * 0.25;
                tempVec.multiplyScalar(displacement);
                break;

            case SHAPES.TORUS:
                // í† ëŸ¬ìŠ¤: íšŒì „ ë‚˜ì„  íŒŒë™
                const angle = Math.atan2(oz, ox);
                const torusWave = Math.sin(angle * (3 + currentY.y4 * 3) + t * 2) * currentY.y2;
                const radialPulse = Math.sin(oy * 5 + t * 3) * currentY.y3 * 0.15;
                const scale = 1 + (torusWave * 0.2 + radialPulse + loudness * 0.2);
                tempVec.x = ox * scale;
                tempVec.z = oz * scale;
                tempVec.y = oy * (1 + torusWave * 0.3 + loudness * 0.15);
                break;

            case SHAPES.CONE:
                // ì›ë¿”: ë†’ì´ì— ë”°ë¥¸ ì°¨ë“± ë³€í˜•
                const heightFactor = (oy + 1) / 2; // 0~1 ì •ê·œí™”
                const coneWave = Math.sin(Math.atan2(oz, ox) * (4 + currentY.y4 * 3) + t) * currentY.y2;
                const heightWave = Math.sin(oy * 3 + t * 2) * currentY.y3 * 0.2;
                const coneScale = 1 + (coneWave * 0.25 + heightWave) * heightFactor + loudness * 0.3;
                tempVec.x = ox * coneScale;
                tempVec.z = oz * coneScale;
                tempVec.y = oy * (1 + Math.sin(t) * currentY.y2 * 0.1 + loudness * 0.2);
                break;

            case SHAPES.CYLINDER:
                // ì›ê¸°ë‘¥: ì„¸ë¡œ íŒŒë™ + íšŒì „ ì™œê³¡
                const cylAngle = Math.atan2(oz, ox);
                const cylWave = Math.sin(cylAngle * (5 + currentY.y4 * 3) + oy * 2 + t * 2) * currentY.y2;
                const verticalWave = Math.sin(oy * 4 + t * 3) * currentY.y3 * 0.15;
                const cylScale = 1 + cylWave * 0.25 + verticalWave + loudness * 0.25;
                tempVec.x = ox * cylScale;
                tempVec.z = oz * cylScale;
                break;

            case SHAPES.OCTAHEDRON:
                // íŒ”ë©´ì²´: ê¼­ì§€ì  ê¸°ë°˜ ë³µì¡í•œ ë³€í˜•
                tempVec.normalize();
                const octWave1 = Math.sin(tempVec.x * 5 + t) * Math.cos(tempVec.y * 5 + t);
                const octWave2 = Math.sin(tempVec.z * 5 + t * 1.5) * currentY.y4 * 0.3;
                const octRough = (Math.sin(t * 15) * 0.05) * currentY.y3;
                displacement = 1.2 + octWave1 * currentY.y2 * 0.4 + octWave2 + octRough + loudness * 0.35;
                tempVec.set(ox, oy, oz).normalize().multiplyScalar(displacement);
                break;
        }

        pos.setXYZ(i, tempVec.x, tempVec.y, tempVec.z);
    }

    // íšŒì „ ì†ë„ë„ í˜•íƒœì— ë”°ë¼ ë‹¤ë¥´ê²Œ
    const rotationSpeed = 0.005 + (currentY.y1 * 0.05);
    currentMesh.rotation.y += rotationSpeed;

    if (shapeType === SHAPES.TORUS || shapeType === SHAPES.CYLINDER) {
        currentMesh.rotation.x += rotationSpeed * 0.3;
    }

    pos.needsUpdate = true;
}

function confirmTraining(useAutoShape = false) {
    console.log('=== Confirming training data ===');

    // recordedX ê²€ì¦
    if (!recordedX || recordedX.count === 0 ||
        isNaN(recordedX.loudness) ||
        isNaN(recordedX.pitch) ||
        isNaN(recordedX.brightness) ||
        isNaN(recordedX.roughness)) {
        alert('Recording data is invalid. Please record again.');
        console.error('Invalid recordedX:', recordedX);
        return;
    }

    // brain ìƒíƒœ í™•ì¸
    if (!brain || !brain.data || !Array.isArray(brain.data.training)) {
        console.error('CRITICAL: Brain not initialized properly');
        alert('Neural network not ready. Please refresh the page and try again.');
        return;
    }

    // í˜•íƒœ ê°’ ê²°ì •: Auto ëª¨ë“œì—ì„œëŠ” í•™ìŠµëœ ëª¨ë¸ ë˜ëŠ” ê·œì¹™ ê¸°ë°˜, ìˆ˜ë™ ëª¨ë“œì—ì„œëŠ” ìŠ¬ë¼ì´ë” ê°’
    let shapeValue;
    if (useAutoShape) {
        // ì´ë¯¸ UIì— í‘œì‹œëœ ê°’ ì‚¬ìš© (stopRecordingì—ì„œ ì´ë¯¸ ë¶„ë¥˜ë¨)
        shapeValue = parseFloat(document.getElementById('shape-selector').value);
        console.log(`Using auto-classified shape: ${SHAPE_NAMES[shapeValue]} (${shapeValue})`);
    } else {
        shapeValue = parseFloat(document.getElementById('shape-selector').value);
    }

    const labels = {
        y1: parseFloat(document.getElementById('y1').value),
        y2: parseFloat(document.getElementById('y2').value),
        y3: parseFloat(document.getElementById('y3').value),
        y4: parseFloat(document.getElementById('y4').value),
        shape: shapeValue
    };

    const inputArray = [recordedX.loudness, recordedX.pitch, recordedX.brightness, recordedX.roughness];
    const outputArray = [labels.y1, labels.y2, labels.y3, labels.y4, labels.shape];

    // ë°ì´í„° ê²€ì¦
    if (inputArray.length !== 4 || outputArray.length !== 5) {
        console.error('ERROR: Wrong array dimensions!');
        alert('Data dimension error. Please refresh and try again.');
        return;
    }

    if (inputArray.some(v => typeof v !== 'number' || isNaN(v)) ||
        outputArray.some(v => typeof v !== 'number' || isNaN(v))) {
        console.error('ERROR: Data contains non-numbers or NaN!');
        alert('Data validation error. Please refresh and try again.');
        return;
    }

    // customTrainingDataì— ì €ì¥
    const dataItem = {
        xs: [...inputArray],
        ys: [...outputArray]
    };

    customTrainingData.push(dataItem);
    console.log(`âœ“ Added to customTrainingData (${customTrainingData.length} total)`);

    // í•™ìŠµ ë°ì´í„° ìë™ ì €ì¥
    saveTrainingData();
    updateDataCount();

    const actualCount = customTrainingData.length;
    console.log(`Successfully saved! Total samples: ${actualCount}`);

    // [ê°œì„ ë¨] ê¸°ì¡´ brainì— ìƒˆ ë°ì´í„°ë§Œ ì¶”ê°€í•˜ê³  ì¦ë¶„ í•™ìŠµ
    console.log('Adding new data to existing brain...');

    // brainì— ìƒˆ ë°ì´í„° ì¶”ê°€
    brain.addData(inputArray, outputArray);

    // [ìˆ˜ì •ë¨] í•­ìƒ ì •ê·œí™” (ë°ì´í„° ê°œìˆ˜ ë¬´ê´€)
    brain.normalizeData();

    updateStatus('statusTraining', 'status-recording');

    // [ê°œì„ ë¨] ì ì‘í˜• epochs: ë°ì´í„° ìˆ˜ì— ë”°ë¼ ì¡°ì • (ë” ë§ì€ í•™ìŠµìœ¼ë¡œ ì•ˆì •ì„± í™•ë³´)
    const epochs = customTrainingData.length < 10 ? 50 : 30;
    brain.train({ epochs: epochs }, () => {
        console.log('Training complete!');
        isModelTrained = true;

        // í•™ìŠµëœ ëª¨ë¸ ì €ì¥
        saveModel();

        alert(`âœ“ Training Complete!\n\nSaved ${actualCount} sample(s) to storage.\nModel is ready for predictions.`);
        state = 'IDLE';

        if(audioTag) audioTag.pause();

        const t = translations[currentLang];
        document.getElementById('labeling-zone').style.display = "none";
        document.getElementById('btn-main').innerText = t.btnRecord;
        document.getElementById('btn-play').style.display = "none";

        updateStatus('statusActive', 'status-idle');
    });
}

// í•™ìŠµëœ ëª¨ë¸ ì €ì¥ (ml5.js model serialization)
function saveModel() {
    if (!brain || !isModelTrained) {
        console.log('No trained model to save');
        return;
    }

    try {
        brain.save('soundTo3D_model', () => {
            console.log('âœ“ Model saved to browser storage');
        });
    } catch (e) {
        console.error('Model save failed:', e);
    }
}

// ì €ì¥ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
function loadModel() {
    // ml5.jsëŠ” íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ ëª¨ë¸ì„ ë¡œë“œí•˜ë¯€ë¡œ,
    // ë¸Œë¼ìš°ì € í™˜ê²½ì—ì„œëŠ” IndexedDB ê°™ì€ ë°©ë²•ì´ í•„ìš”
    // ëŒ€ì‹  ìš°ë¦¬ëŠ” customTrainingDataê°€ ìˆìœ¼ë©´ ì¬í•™ìŠµí•˜ëŠ” ë°©ì‹ ì‚¬ìš©
    console.log('Model loading from localStorage not directly supported by ml5.js in browser');
    console.log('Will retrain from customTrainingData if needed');
}

// í•™ìŠµ ë°ì´í„°ë¥¼ localStorageì— ì €ì¥ (customTrainingData ì‚¬ìš©)
function saveTrainingData() {
    try {
        const saveObj = {
            version: 3, // ìƒˆ ë²„ì „ (customTrainingData ì‚¬ìš©)
            count: customTrainingData.length,
            data: customTrainingData,
            timestamp: Date.now()
        };

        localStorage.setItem('soundTo3D_trainingData', JSON.stringify(saveObj));
        console.log(`âœ“ Saved ${customTrainingData.length} samples to localStorage`);
    } catch (e) {
        console.error('Save failed:', e);
    }
}

// localStorageì—ì„œ í•™ìŠµ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ìë™ ì¬í•™ìŠµ
function loadTrainingData() {
    const saved = localStorage.getItem('soundTo3D_trainingData');
    if (!saved) {
        console.log('No saved training data');
        return;
    }

    try {
        const saveObj = JSON.parse(saved);

        if (!saveObj || !Array.isArray(saveObj.data)) {
            console.warn('Invalid data, clearing');
            localStorage.removeItem('soundTo3D_trainingData');
            return;
        }

        // customTrainingDataì— ë¡œë“œ
        customTrainingData = [];

        for (let i = 0; i < saveObj.data.length; i++) {
            const item = saveObj.data[i];

            if (!item || !Array.isArray(item.xs) || !Array.isArray(item.ys)) continue;
            if (item.xs.length !== 4 || item.ys.length !== 5) continue;

            // ìœ íš¨ì„± ì²´í¬
            let valid = true;
            for (let j = 0; j < 4; j++) {
                if (typeof item.xs[j] !== 'number' || isNaN(item.xs[j])) {
                    valid = false;
                    break;
                }
            }
            if (valid) {
                for (let j = 0; j < 5; j++) {
                    if (typeof item.ys[j] !== 'number' || isNaN(item.ys[j])) {
                        valid = false;
                        break;
                    }
                }
            }

            if (valid) {
                customTrainingData.push(item);
            }
        }

        console.log(`âœ“ Loaded ${customTrainingData.length} samples into customTrainingData`);

        // [ê°œì„ ë¨] ë°ì´í„°ê°€ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ brain ì¬í•™ìŠµ
        if (customTrainingData.length >= AUDIO_CONSTANTS.MIN_TRAINING_SAMPLES) {
            console.log('Auto-retraining brain with loaded data...');

            // brainì— ëª¨ë“  ë°ì´í„° ì¶”ê°€
            for (let i = 0; i < customTrainingData.length; i++) {
                brain.addData(customTrainingData[i].xs, customTrainingData[i].ys);
            }

            // ì •ê·œí™”
            brain.normalizeData();

            // [ê°œì„ ë¨] ë°±ê·¸ë¼ìš´ë“œ í•™ìŠµ - ì¶©ë¶„í•œ epochsë¡œ ì•ˆì •ì„± í™•ë³´
            const epochs = customTrainingData.length < 10 ? 50 : 30;
            brain.train({ epochs: epochs }, () => {
                isModelTrained = true;
                console.log(`âœ“ Auto-training complete with ${customTrainingData.length} samples`);
            });
        }
    } catch (e) {
        console.error('Load failed:', e);
        localStorage.removeItem('soundTo3D_trainingData');
    }
}

// í•™ìŠµ ë°ì´í„° ê°œìˆ˜ ì—…ë°ì´íŠ¸
function updateDataCount() {
    const countEl = document.getElementById('data-count');
    if (countEl) {
        countEl.innerText = customTrainingData.length;
    }
}

// ëª¨ë“  í•™ìŠµ ë°ì´í„° ì‚­ì œ
function clearAllData() {
    if (!confirm('Delete all training data?\nThis action cannot be undone.')) {
        return;
    }

    console.log('=== Clearing all training data ===');

    // localStorage ì‚­ì œ
    localStorage.removeItem('soundTo3D_trainingData');
    console.log('âœ“ localStorage cleared');

    // customTrainingData ì´ˆê¸°í™”
    const oldLength = customTrainingData.length;
    customTrainingData = [];
    console.log(`âœ“ Custom training data reset (${oldLength} â†’ 0)`);

    updateDataCount();
    alert('âœ“ All training data deleted successfully.');
}

// ê¸´ê¸‰ ë³µêµ¬: ì™„ì „ ì´ˆê¸°í™” (ë¸Œë¼ìš°ì € ì½˜ì†”ì—ì„œ ì‚¬ìš©)
function emergencyReset() {
    console.log('=== EMERGENCY RESET ===');

    // localStorage ì‚­ì œ
    localStorage.clear();
    console.log('âœ“ All localStorage cleared');

    // customTrainingData ì´ˆê¸°í™”
    customTrainingData = [];
    console.log('âœ“ customTrainingData cleared');

    // brain ì¬ìƒì„±
    if (typeof ml5 !== 'undefined') {
        brain = ml5.neuralNetwork({
            inputs: 4,
            outputs: 5,
            task: 'regression',
            debug: false,
            hiddenUnits: 8,           // ë” ì‘ì€ hidden layer (ê³¼ì í•© ë°©ì§€)
            learningRate: 0.01,       // ë‚®ì€ learning rate (ì•ˆì •ì  í•™ìŠµ)
            activationHidden: 'relu', // ReLU activation (í•™ìŠµ ì•ˆì •ì„±)
            activationOutput: 'sigmoid' // 0-1 ë²”ìœ„ ì¶œë ¥ ë³´ì¥
        });
        console.log('âœ“ Brain recreated');

        const waitAndUpdate = () => {
            if (brain.data && Array.isArray(brain.data.training)) {
                updateDataCount();
                console.log('âœ“ Emergency reset complete');
                alert('Emergency reset complete. Everything has been reset.');
            } else {
                setTimeout(waitAndUpdate, 100);
            }
        };
        setTimeout(waitAndUpdate, 100);
    } else {
        updateDataCount();
        alert('Emergency reset complete. Please reload the page.');
    }
}

// CSVë¡œ ë°ì´í„° ë‚´ë³´ë‚´ê¸° (customTrainingData ì‚¬ìš©)
function exportCSV() {
    if (customTrainingData.length === 0) {
        alert('No data to export.');
        return;
    }

    let csv = 'loudness,pitch,brightness,roughness,y1,y2,y3,y4,shape\n';

    for (let i = 0; i < customTrainingData.length; i++) {
        const item = customTrainingData[i];
        if (!item || !item.xs || !item.ys) continue;

        const xs = item.xs;
        const ys = item.ys;

        if (xs.length === 4 && ys.length === 5) {
            csv += `${xs[0]},${xs[1]},${xs[2]},${xs[3]},`;
            csv += `${ys[0]},${ys[1]},${ys[2]},${ys[3]},${ys[4]}\n`;
        }
    }

    const blob = new Blob([csv], { type: 'text/csv' });
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = `soundTo3D_data_${Date.now()}.csv`;
    a.click();
    URL.revokeObjectURL(url);
}

// [ê°œì„ ë¨] í˜•íƒœ ì„ íƒê¸° ë³€ê²½ ì‹œ ì‹¤ì‹œê°„ ë¯¸ë¦¬ë³´ê¸° (ë””ë°”ìš´ìŠ¤ ì¶”ê°€)
function onShapeChange() {
    if (state === 'REVIEWING') {
        // ë””ë°”ìš´ìŠ¤: ë¹ ë¥¸ ì—°ì† ë³€ê²½ ì‹œ ë§ˆì§€ë§‰ ê°’ë§Œ ì²˜ë¦¬
        if (shapeChangeTimer) {
            clearTimeout(shapeChangeTimer);
        }

        const shapeValue = parseInt(document.getElementById('shape-selector').value);
        document.getElementById('shape-name').innerText = SHAPE_NAMES[shapeValue];

        shapeChangeTimer = setTimeout(() => {
            createShape(shapeValue);
            shapeChangeTimer = null;
        }, 100); // 100ms ë””ë°”ìš´ìŠ¤
    }
}

// ìë™ í˜•íƒœ ë¶„ë¥˜ í† ê¸€
function onAutoShapeToggle() {
    const isAutoOn = document.getElementById('auto-shape').checked;
    const shapeSelector = document.getElementById('shape-selector');
    const y1Slider = document.getElementById('y1');
    const y2Slider = document.getElementById('y2');
    const y3Slider = document.getElementById('y3');
    const y4Slider = document.getElementById('y4');

    if (isAutoOn) {
        // ìë™ ëª¨ë“œ: ëª¨ë“  ìŠ¬ë¼ì´ë” ë¹„í™œì„±í™”
        shapeSelector.disabled = true;
        shapeSelector.style.opacity = '0.5';
        y1Slider.disabled = true;
        y1Slider.style.opacity = '0.5';
        y2Slider.disabled = true;
        y2Slider.style.opacity = '0.5';
        y3Slider.disabled = true;
        y3Slider.style.opacity = '0.5';
        y4Slider.disabled = true;
        y4Slider.style.opacity = '0.5';

        // [ê°œì„ ë¨] í˜„ì¬ ë…¹ìŒëœ ì†Œë¦¬ë¡œ ìë™ ë¶„ë¥˜ (ìºì‹œëœ ê°’ ìš°ì„  ì‚¬ìš©, ê³µí†µ í•¨ìˆ˜ í™œìš©)
        if (state === 'REVIEWING' && recordedX && recordedX.count > 0) {
            if (cachedAutoShape !== null) {
                // ì´ë¯¸ ê³„ì‚°ëœ ê°’ì´ ìˆìœ¼ë©´ ìºì‹œ ì‚¬ìš©
                shapeSelector.value = cachedAutoShape;
                document.getElementById('shape-name').innerText = SHAPE_NAMES[cachedAutoShape];
                createShape(cachedAutoShape);
                console.log(`ğŸ“¦ Using cached shape: ${SHAPE_NAMES[cachedAutoShape]}`);
            } else {
                // ìºì‹œ ì—†ìœ¼ë©´ ìƒˆë¡œ ê³„ì‚°
                performAutoClassification();
            }
        }
    } else {
        // ìˆ˜ë™ ëª¨ë“œ: ëª¨ë“  ìŠ¬ë¼ì´ë” í™œì„±í™”
        shapeSelector.disabled = false;
        shapeSelector.style.opacity = '1';
        y1Slider.disabled = false;
        y1Slider.style.opacity = '1';
        y2Slider.disabled = false;
        y2Slider.style.opacity = '1';
        y3Slider.disabled = false;
        y3Slider.style.opacity = '1';
        y4Slider.disabled = false;
        y4Slider.style.opacity = '1';
    }
}

// confirmTraining í˜¸ì¶œ ì‹œ ìë™ ë¶„ë¥˜ ì˜µì…˜ í™•ì¸
window.confirmTrainingWrapper = function() {
    const useAutoShape = document.getElementById('auto-shape').checked;
    confirmTraining(useAutoShape);
}

// ì–¸ì–´ ì „í™˜
let currentLang = 'en';

const translations = {
    en: {
        langBtn: 'í•œêµ­ì–´',
        title: 'IML Experiment Panel',
        btnEngine: 'Initialize Audio Engine',
        btnRecord: 'Start Recording',
        btnStop: 'Stop Recording',
        btnReRecord: 'Re-record',
        btnPlay: 'â–¶ Play Recording',
        btnPause: 'â¸ Pause',
        labelInstruction: 'Define visual characteristics of the recorded sound',
        y1Left: 'Smooth', y1Right: 'Angular',
        y2Left: 'Flat', y2Right: 'Sharp',
        y3Left: 'Smooth', y3Right: 'Rough',
        y4Left: 'Simple', y4Right: 'Complex',
        btnConfirm: 'Confirm Training Data',
        dataLabel: 'Training Data:',
        samplesLabel: 'samples',
        btnExport: 'Export Data (CSV)',
        btnClear: 'Clear All Training Data',
        statusReady: 'Ready - Click to Initialize Audio Engine',
        statusInit: 'Initializing Audio Engine...',
        statusActive: 'Ready - Microphone Active',
        statusRecording: 'Recording...',
        statusReview: 'Review - Awaiting Labels',
        statusTraining: 'Training Neural Network...'
    },
    ko: {
        langBtn: 'English',
        title: 'IML ì‹¤í—˜ íŒ¨ë„',
        btnEngine: 'ì˜¤ë””ì˜¤ ì—”ì§„ ê°€ë™',
        btnRecord: 'ë…¹ìŒ ì‹œì‘',
        btnStop: 'ë…¹ìŒ ì¤‘ë‹¨ (Stop)',
        btnReRecord: 'ë‹¤ì‹œ ë…¹ìŒí•˜ê¸°',
        btnPlay: 'â–¶ ë…¹ìŒ ì¬ìƒ',
        btnPause: 'â¸ ì¼ì‹œì •ì§€',
        labelInstruction: 'ë°©ê¸ˆ ì†Œë¦¬ì˜ ì‹œê°ì  í˜•ì§ˆì„ ê²°ì •í•˜ì„¸ìš”',
        y1Left: 'ë‘¥ê·¼', y1Right: 'ê°ì§„',
        y2Left: 'í‰í‰', y2Right: 'ë¾°ì¡±',
        y3Left: 'ë§¤ëˆ', y3Right: 'ê±°ì¹¨',
        y4Left: 'ë‹¨ìˆœ', y4Right: 'ë³µì¡',
        btnConfirm: 'í•™ìŠµ ë°ì´í„°ë¡œ í™•ì •',
        dataLabel: 'í•™ìŠµ ë°ì´í„°:',
        samplesLabel: 'ê°œ',
        btnExport: 'ë°ì´í„° ë‚´ë³´ë‚´ê¸° (CSV)',
        btnClear: 'ëª¨ë“  í•™ìŠµ ë°ì´í„° ì‚­ì œ',
        statusReady: 'ì¤€ë¹„ë¨ - ì—”ì§„ ê°€ë™ í´ë¦­',
        statusInit: 'ì—”ì§„ ì´ˆê¸°í™” ì¤‘...',
        statusActive: 'ëŒ€ê¸° ì¤‘ (ë…¹ìŒ ê°€ëŠ¥)',
        statusRecording: 'ë…¹ìŒ ì¤‘...',
        statusReview: 'ë¦¬ë·° ì¤‘ (ë¼ë²¨ë§ ëŒ€ê¸°)',
        statusTraining: 'AI í•™ìŠµ ì¤‘...'
    }
};

function toggleLanguage() {
    currentLang = currentLang === 'en' ? 'ko' : 'en';
    const t = translations[currentLang];

    document.getElementById('lang-toggle').innerText = t.langBtn;
    document.getElementById('title').innerText = t.title;
    document.getElementById('btn-engine').innerText = t.btnEngine;
    document.getElementById('label-instruction').innerText = t.labelInstruction;

    document.querySelector('.y1-left').innerText = t.y1Left;
    document.querySelector('.y1-right').innerText = t.y1Right;
    document.querySelector('.y2-left').innerText = t.y2Left;
    document.querySelector('.y2-right').innerText = t.y2Right;
    document.querySelector('.y3-left').innerText = t.y3Left;
    document.querySelector('.y3-right').innerText = t.y3Right;
    document.querySelector('.y4-left').innerText = t.y4Left;
    document.querySelector('.y4-right').innerText = t.y4Right;

    document.getElementById('btn-confirm').innerText = t.btnConfirm;
    document.getElementById('data-label').innerText = t.dataLabel;
    document.getElementById('samples-label').innerText = t.samplesLabel;
    document.getElementById('btn-export').innerText = t.btnExport;
    document.getElementById('btn-clear').innerText = t.btnClear;

    // ìƒíƒœì— ë”°ë¼ ë²„íŠ¼ í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
    if (state === 'IDLE') {
        document.getElementById('btn-main').innerText = t.btnRecord;
    } else if (state === 'RECORDING') {
        document.getElementById('btn-main').innerText = t.btnStop;
    } else if (state === 'REVIEWING') {
        document.getElementById('btn-main').innerText = t.btnReRecord;
    }

    // í˜„ì¬ ìƒíƒœ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
    updateStatusText();
}

function updateStatusText() {
    const t = translations[currentLang];
    const statusEl = document.getElementById('status');
    const currentClass = statusEl.className;

    if (currentClass.includes('status-idle')) {
        if (brain) {
            statusEl.innerText = t.statusActive;
        } else {
            statusEl.innerText = t.statusReady;
        }
    } else if (currentClass.includes('status-recording')) {
        if (statusEl.innerText.includes('Training') || statusEl.innerText.includes('í•™ìŠµ')) {
            statusEl.innerText = t.statusTraining;
        } else {
            statusEl.innerText = t.statusRecording;
        }
    } else if (currentClass.includes('status-review')) {
        statusEl.innerText = t.statusReview;
    }
}